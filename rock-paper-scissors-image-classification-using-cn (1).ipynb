{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list the files in the folder\n",
    "#!ls ../input/rock-paper-scissors-dataset/Rock-Paper-Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the files in the folder\n",
    "#!ls ../input/rock-paper-scissors-dataset/Rock-Paper-Scissors/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'C:\\Users\\himan\\Rock Paper Scissors\\Rock-Paper-Scissors'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'test')\n",
    "test_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "paper_dir = os.path.join(train_dir, 'paper')\n",
    "rock_dir = os.path.join(train_dir, 'rock')\n",
    "scissors_dir = os.path.join(train_dir, 'scissors')\n",
    "\n",
    "paper_imgs = os.listdir(paper_dir)\n",
    "rock_imgs = os.listdir(rock_dir)\n",
    "scissors_imgs = os.listdir(scissors_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, img_path in enumerate(paper_imgs[:5]):\n",
    "    sp = plt.subplot(1, 5, i+1)\n",
    "    img = mpimg.imread(os.path.join(paper_dir, img_path))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, img_path in enumerate(rock_imgs[:5]):\n",
    "    sp = plt.subplot(1, 5, i+1)\n",
    "    img = mpimg.imread(os.path.join(rock_dir, img_path))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i, img_path in enumerate(scissors_imgs[:5]):\n",
    "    sp = plt.subplot(1, 5, i+1)\n",
    "    img = mpimg.imread(os.path.join(scissors_dir, img_path))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2)\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "Found 372 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(TARGET_SIZE, TARGET_SIZE), \n",
    "                                                    batch_size=BATCH_SIZE, \n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "val_generator = validation_datagen.flow_from_directory(val_dir,\n",
    "                                                       target_size=(TARGET_SIZE, TARGET_SIZE), \n",
    "                                                       batch_size=BATCH_SIZE, \n",
    "                                                       shuffle=True,\n",
    "                                                       class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,363\n",
      "Trainable params: 167,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 15s 188ms/step - loss: 0.6697 - accuracy: 0.7087 - val_loss: 0.4086 - val_accuracy: 0.8199\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 16s 197ms/step - loss: 0.1041 - accuracy: 0.9694 - val_loss: 0.2875 - val_accuracy: 0.8790\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 16s 208ms/step - loss: 0.0561 - accuracy: 0.9849 - val_loss: 0.1965 - val_accuracy: 0.9220\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 17s 210ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.2819 - val_accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 17s 219ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.3490 - val_accuracy: 0.8952\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 17s 215ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.4111 - val_accuracy: 0.8737\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 18s 225ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4098 - val_accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 19s 237ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.7534 - val_accuracy: 0.8441\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.4841 - val_accuracy: 0.8656\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 18s 225ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.9784 - val_accuracy: 0.7124\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.savefig('./foo.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('rock_paper_scissors_cmp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio \n",
    "import requests\n",
    "import urllib\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=tf.keras.models.load_model(r'C:\\Users\\himan\\Rock Paper Scissors\\rock_paper_scissors_cmp.h5')\n",
    "labels=['Paper','Rock','Scissors']\n",
    "\n",
    "def classify_image(inp):\n",
    "    # Resize the input image to (64, 64)\n",
    "    inp = Image.fromarray(inp)\n",
    "    inp = inp.resize((64, 64))\n",
    "    inp = np.array(inp)\n",
    "\n",
    "    # Preprocess the input image\n",
    "    inp = inp[None, ...]\n",
    "    inp = tf.keras.applications.inception_v3.preprocess_input(inp)\n",
    "\n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(inp).flatten()\n",
    "    return {labels[i]: float(prediction[i]) for i in range(no_classes)}\n",
    "\n",
    "\n",
    "import gradio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def classify_image(inp):\n",
    "    if inp is None:\n",
    "        # Handle the case where inp is None\n",
    "        return {}\n",
    "    # Resize the input image to (64, 64)\n",
    "    inp = Image.fromarray(inp)\n",
    "    inp = inp.resize((64, 64))\n",
    "    inp = np.array(inp)\n",
    "\n",
    "    # Preprocess the input image\n",
    "    inp = inp[None, ...]\n",
    "    inp = tf.keras.applications.inception_v3.preprocess_input(inp)\n",
    "\n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(inp).flatten()\n",
    "    no_classes = 3  # Set this to the number of classes in your model's output\n",
    "    return {labels[i]: float(prediction[i]) for i in range(no_classes)}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "Could not create share link. Missing file: C:\\Users\\himan\\anaconda3\\lib\\site-packages\\gradio\\frpc_windows_amd64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_windows_amd64.exe\n",
      "2. Rename the downloaded file to: frpc_windows_amd64_v0.2\n",
      "3. Move the file to this location: C:\\Users\\himan\\anaconda3\\lib\\site-packages\\gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = gradio.components.Image(shape=(224, 224))\n",
    "label = gradio.components.Label(num_top_classes=3)\n",
    "\n",
    "gradio.Interface(fn=classify_image, inputs=image, outputs=label, interpretation=\"default\").launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
